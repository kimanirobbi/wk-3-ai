{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvbkiK4YVg6uMjRUVA14a1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimanirobbi/wk-3-ai/blob/main/Task_1_Classical_ML_(Iris_Decision_Tree).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCWw2OjFHeBn",
        "outputId": "5c277811-4b2b-4473-dc69-601cc6a7cae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 1: Classical ML (Decision Tree on Iris) ---\n",
            "Features (X) shape: (150, 4)\n",
            "Target (y) shape: (150,)\n",
            "Target Species: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "First 5 rows of data:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "Missing values imputation complete (median strategy applied).\n",
            "Encoded classes: [0 1 2]\n",
            "\n",
            "Training samples: 105, Testing samples: 45\n",
            "Decision Tree Classifier training complete.\n",
            "\n",
            "--- Model Evaluation Results (Decision Tree) ---\n",
            "Accuracy:  0.9333\n",
            "Precision (Macro): 0.9444\n",
            "Recall (Macro):    0.9333\n",
            "\n",
            "Test Sample Index 0:\n",
            "Features: [7.3 2.9 6.3 1.8]\n",
            "True Species: virginica (Label 2)\n",
            "Predicted Species: virginica (Label 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Data Loading and Initial Inspection\n",
        "# -----------------------------------------------------------\n",
        "print(\"--- Task 1: Classical ML (Decision Tree on Iris) ---\")\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "print(f\"Target Species: {target_names}\")\n",
        "print(\"\\nFirst 5 rows of data:\")\n",
        "print(X.head())\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Data Preprocessing (Handling Missing Values & Encoding)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 2a. Simulating and Handling Missing Values (Best Practice Example)\n",
        "# Iris dataset is clean, so we simulate a missing value for demonstration\n",
        "X_with_nans = X.copy()\n",
        "# Introduce one NaN value in the first feature\n",
        "X_with_nans.iloc[1, 0] = np.nan\n",
        "\n",
        "# Initialize Imputer (using median for robustness against outliers)\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "X_imputed = imputer.fit_transform(X_with_nans)\n",
        "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "print(\"\\nMissing values imputation complete (median strategy applied).\")\n",
        "\n",
        "# 2b. Label Encoding (Iris targets are already numeric, but we demonstrate)\n",
        "# If the target was a string array (e.g., ['setosa', 'versicolor', 'virginica']),\n",
        "# we would use LabelEncoder or OneHotEncoder.\n",
        "le = LabelEncoder()\n",
        "# Since y is already numeric, this step serves to map the integers to themselves\n",
        "# but confirms the encoding pipeline if needed for string labels.\n",
        "y_encoded = le.fit_transform(y)\n",
        "print(f\"Encoded classes: {le.classes_}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Data Splitting and Model Training\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Split the data into training and testing sets (70/30 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
        ")\n",
        "print(f\"\\nTraining samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n",
        "\n",
        "# Initialize and train the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "print(\"Decision Tree Classifier training complete.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Prediction and Evaluation\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# Use 'macro' average for precision/recall since this is a multi-class problem\n",
        "# 'macro' calculates metrics for each label and finds their unweighted mean.\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n--- Model Evaluation Results (Decision Tree) ---\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision (Macro): {precision:.4f}\")\n",
        "print(f\"Recall (Macro):    {recall:.4f}\")\n",
        "\n",
        "# Example of a single prediction\n",
        "sample_index = 0\n",
        "# Create a DataFrame with the same columns as X_train for prediction\n",
        "sample_features = pd.DataFrame([X_test.iloc[sample_index]], columns=X_train.columns)\n",
        "sample_prediction = dt_classifier.predict(sample_features)[0]\n",
        "# Access the element using standard NumPy array indexing\n",
        "true_label = y_test[sample_index]\n",
        "print(f\"\\nTest Sample Index {sample_index}:\")\n",
        "print(f\"Features: {X_test.iloc[sample_index].values}\")\n",
        "print(f\"True Species: {target_names[true_label]} (Label {true_label})\")\n",
        "print(f\"Predicted Species: {target_names[sample_prediction]} (Label {sample_prediction})\")"
      ]
    }
  ]
}