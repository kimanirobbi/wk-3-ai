{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimanirobbi/wk-3-ai/blob/main/bonus_task_flask_deployment_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This script outlines the structure for the Bonus Task: Deploying the MNIST model\n",
        "# using Flask. To run this, you would need to save the model from Task 2 first.\n",
        "#\n",
        "# Prerequisites:\n",
        "# 1. Install Flask and TensorFlow: pip install flask tensorflow numpy\n",
        "# 2. Save the trained model from task2_deep_learning_cnn.py:\n",
        "#    model.save('mnist_cnn_model.h5')\n",
        "# 3. Create a 'static' folder for CSS/JS (optional) and a 'templates' folder for index.html\n",
        "\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Configuration for Flask and Model Loading\n",
        "app = Flask(__name__)\n",
        "# The model path should be updated once the model is trained and saved\n",
        "MODEL_PATH = 'mnist_cnn_model.h5'\n",
        "\n",
        "# Load the trained model globally when the app starts\n",
        "try:\n",
        "    # Suppress TensorFlow logging to keep console clean\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    # Load the model structure and weights\n",
        "    MODEL = load_model(MODEL_PATH)\n",
        "    MODEL.predict(np.zeros((1, 28, 28, 1))) # Warm up the model\n",
        "    print(f\"Successfully loaded model from: {MODEL_PATH}\")\n",
        "except Exception as e:\n",
        "    # If the model file is not found (common when running this file alone)\n",
        "    MODEL = None\n",
        "    print(f\"Warning: Could not load the model file ({MODEL_PATH}).\")\n",
        "    print(\"To run this, ensure the model is saved correctly after Task 2.\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Helper Functions\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "def preprocess_image(img_data_url):\n",
        "    \"\"\"Converts a base64 Data URL (from a canvas) into a preprocessed numpy array.\"\"\"\n",
        "\n",
        "    # The image data is split to get the base64 part\n",
        "    encoded_data = img_data_url.split(',')[1]\n",
        "    binary_data = base64.b64decode(encoded_data)\n",
        "\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(io.BytesIO(binary_data))\n",
        "\n",
        "    # The image from canvas is usually 280x280 (or similar) and RGBA.\n",
        "    # 1. Resize to 28x28 (required by MNIST model)\n",
        "    # 2. Convert to grayscale ('L' mode)\n",
        "    # 3. Invert colors (MNIST is black text on white background, canvas is usually reverse)\n",
        "    img = img.resize((28, 28)).convert('L')\n",
        "\n",
        "    # Convert image to numpy array, normalize, and invert colors (255 - pixel_value)\n",
        "    img_array = np.array(img).astype('float32')\n",
        "    img_array = 255.0 - img_array # Invert for black background\n",
        "\n",
        "    # Normalize to 0-1 range and reshape for CNN (1, 28, 28, 1)\n",
        "    img_array /= 255.0\n",
        "    img_array = img_array.reshape(1, 28, 28, 1)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Flask Routes\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Renders the main page with the drawing canvas.\"\"\"\n",
        "    # In a real deployment, you would need a file named 'index.html' in a 'templates' folder.\n",
        "    # For this deliverable, we provide the full HTML/JS in a single function return (simulated)\n",
        "    return render_template('index_simulated.html')\n",
        "\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    \"\"\"Handles the prediction request from the web interface.\"\"\"\n",
        "    if MODEL is None:\n",
        "        return jsonify({'error': 'Model not loaded.'}), 500\n",
        "\n",
        "    data = request.get_json()\n",
        "    img_data_url = data.get('image')\n",
        "\n",
        "    if not img_data_url:\n",
        "        return jsonify({'error': 'No image data provided.'}), 400\n",
        "\n",
        "    try:\n",
        "        # Preprocess the image\n",
        "        processed_image = preprocess_image(img_data_url)\n",
        "\n",
        "        # Make the prediction\n",
        "        predictions = MODEL.predict(processed_image)\n",
        "        predicted_class = int(np.argmax(predictions[0]))\n",
        "        confidence = float(np.max(predictions[0]))\n",
        "\n",
        "        # Return the result\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'prediction': predicted_class,\n",
        "            'confidence': f\"{confidence*100:.2f}%\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction Error: {e}\")\n",
        "        return jsonify({'success': False, 'error': str(e)}), 500\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Simulated HTML Template (for demonstration of the deployment concept)\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# Since I cannot generate a separate index.html, I will provide a conceptual\n",
        "# explanation of the front-end needed for the deployment.\n",
        "\n",
        "# Conceptual Front-End (index.html):\n",
        "# 1. <canvas> element for drawing.\n",
        "# 2. JavaScript to handle mouse/touch events to draw on the canvas.\n",
        "# 3. A \"Predict\" button that converts the canvas content to a base64 Data URL.\n",
        "# 4. An AJAX call (fetch/XMLHttpRequest) to send the Data URL to the /predict endpoint.\n",
        "# 5. A display area to show the prediction and confidence score.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n--- Bonus Task: Flask Deployment Setup ---\")\n",
        "    print(\"This script is a conceptual framework.\")\n",
        "    print(f\"To run: Save model as '{MODEL_PATH}' and then execute the script.\")\n",
        "    print(\"Access the app at http://127.0.0.1:5000/\")\n",
        "    # app.run(debug=True) # Uncomment to run the Flask app locally"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not load the model file (mnist_cnn_model.h5).\n",
            "To run this, ensure the model is saved correctly after Task 2.\n",
            "\n",
            "--- Bonus Task: Flask Deployment Setup ---\n",
            "This script is a conceptual framework.\n",
            "To run: Save model as 'mnist_cnn_model.h5' and then execute the script.\n",
            "Access the app at http://127.0.0.1:5000/\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwDW2ezLp6_",
        "outputId": "be6c7164-6e35-49f9-ce42-77f80c94c7ba"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cb2c869",
        "outputId": "7c128279-6b6e-4ba1-8383-4b0b4a1a45ad"
      },
      "source": [
        "%pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python bonus_task_flask_deployment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgwRgXtEjhLd",
        "outputId": "4f4c77f0-90b7-4ab5-8705-9911636b61d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/bonus_task_flask_deployment.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# --- Flask Configuration ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "# FIX: Use os.path methods to ensure the model path is absolute and correct.\n",
        "# This calculates the path relative to where app.py is located.\n",
        "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "MODEL_PATH = os.path.join(BASE_DIR, 'mnist_cnn_model.h5')\n",
        "\n",
        "# Load the trained model globally when the app starts.\n",
        "try:\n",
        "    # Suppress TensorFlow logging to keep console clean\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "    # Load the model structure and weights using the fixed path\n",
        "    MODEL = load_model(MODEL_PATH)\n",
        "    # Warm up the model for the first prediction\n",
        "    MODEL.predict(np.zeros((1, 28, 28, 1)))\n",
        "    print(f\"[INFO] Successfully loaded model from: {MODEL_PATH}\")\n",
        "except Exception as e:\n",
        "    MODEL = None\n",
        "    print(f\"[ERROR] Could not load the model file ({MODEL_PATH}).\")\n",
        "    print(f\"Please ensure the file exists in the same folder as app.py. Error: {e}\")\n",
        "\n",
        "# --- Helper Function for Image Preprocessing (Remains the same) ---\n",
        "def preprocess_image(img_data_url):\n",
        "    \"\"\"Converts a base64 Data URL (from a canvas) into a preprocessed numpy array.\"\"\"\n",
        "\n",
        "    encoded_data = img_data_url.split(',')[1]\n",
        "    binary_data = base64.b64decode(encoded_data)\n",
        "    img = Image.open(io.BytesIO(binary_data))\n",
        "\n",
        "    img = img.resize((28, 28)).convert('L')\n",
        "\n",
        "    img_array = np.array(img).astype('float32')\n",
        "    img_array = 255.0 - img_array # Invert for black background\n",
        "\n",
        "    img_array /= 255.0\n",
        "    img_array = np.clip(img_array, 0, 1)\n",
        "\n",
        "    img_array = img_array.reshape(1, 28, 28, 1)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# --- Flask Routes (Remain the same) ---\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Renders the main template containing the drawing interface.\"\"\"\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    \"\"\"API endpoint to receive canvas data and return the prediction.\"\"\"\n",
        "    if MODEL is None:\n",
        "        return jsonify({'error': 'Model not loaded on server.'}), 500\n",
        "\n",
        "    data = request.get_json()\n",
        "    img_data_url = data.get('image')\n",
        "\n",
        "    if not img_data_url:\n",
        "        return jsonify({'error': 'No image data provided.'}), 400\n",
        "\n",
        "    try:\n",
        "        processed_image = preprocess_image(img_data_url)\n",
        "        predictions = MODEL.predict(processed_image)\n",
        "        predicted_class = int(np.argmax(predictions[0]))\n",
        "        confidence = float(np.max(predictions[0]))\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'prediction': predicted_class,\n",
        "            'confidence': f\"{confidence*100:.2f}%\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction Error: {e}\")\n",
        "        return jsonify({'success': False, 'error': 'Internal server error during prediction.'}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n--- MNIST CNN Deployment Ready ---\")\n",
        "    print(f\"Attempting to load model from: {MODEL_PATH}\")\n",
        "    print(\"If this fails, please ensure 'mnist_cnn_model.h5' is next to app.py.\")\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "mRFwv_sN1JA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}